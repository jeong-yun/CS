stacking algorithm
 - 여러 머신러닝 모델을 결합하여 사용하는 앙상블 기법 중 하나
 - 여러 개의 다른 머신러닝 모델을 결합하여 하나의 메타 모델을 생성하는 방법
 - 장점: 예측력이 높고 안정적인 결과를 제공할 수 있으며, 다양한 종류의 모델을 사용하기 때문에 각 모델의 장점을 효과적으로 취합할 수 있음
 - 단점: 훈련하는 데 많은 계산 비용과 시간이 필요하며, hyperparameter를 조정하고 모델의 복잡성을 관리하는 것이 어려움



Text CNN
 - 자연어 처리(NLP) 분야에서 사용되는 딥러닝 모델 중 하나
 - 텍스트 분류, 감성 분석, 문서 분류 등의 다양한 자연어 처리 문제에서 좋은 성능을 보임
 - 텍스트 데이터가 긴 경우에도 처리 가능
 - 텍스트 데이터를 입력으로 받기 때문에, 단어 사전이나 특성 추출 등의 전처리 과정을 거치지 않아도 되므로 모델을 더욱 간단하게 구현할 수 있음
 - convolution: 특징을 추출하기 위한 연산(특징: 지역적인 정보 유지-> 즉, 특정 구역에서 발생하는 패턴 감지 가능)
  - 연산은 필터(filter) 또는 커널(kernel)이라는 작은 윈도우(window)를 슬라이딩 시키면서 입력 데이터의 부분 영역과 필터 간의 내적(inner product)을 계산
  - 필터의 값은 학습을 통해 자동으로 결정
  - 필터는 입력 데이터에서 특정 패턴을 감지하도록 조정
 - pooling: 추출한 특징을 결합
 - 2D convolution: 이미지에서 발생하는 공간 정보 활용 가능
  - 데이터 형태: 행렬 형태로 표현
  - 데이터가 2차원 평면 상에 표현, 픽셀 간의 공간적인 관계가 중요 -> convolution + spatial pooling 연산 사용
  - Spartial Pooling 연산:  입력 데이터의 공간적인 정보를 유지하면서 크기를 줄이는 방식으로 작동 -> 공간적인 정보를 보존하면서 계산량을 줄일 수 있음
   - Max Pooling
    - 입력 데이터의 크기를 줄이면서 가장 큰 값만을 선택하여 출력 데이터를 생성하는 방식
    - 입력 데이터의 지역적인 특징을 추출하는 데 사용 ->  생성된 출력 데이터는 입력 데이터에서 가장 큰 값을 대표하는 특징을 갖게 됨
    - 이미지 분류 문제에서 자주 사용
    - 특징 1) Translation Invariance: 입력 데이터 내의 최대값을 선택하기 때문에 입력 데이터가 약간 이동하더라도 출력 결과가 거의 변하지 않음
    - 특징 2) Reduction of Overfitting: 입력 데이터의 크기를 줄이는 효과가 있어, 모델이 입력 데이터의 세부적인 특징에 과도하게 의존하지 않도록 도와줌
    - 특징 3) Computationally Efficient: 입력 데이터의 크기를 줄이는 작업을 수행하기 때문에, 모델이 처리해야 할 계산량을 줄여줌
   - Average Pooling
    - 입력 데이터 내에서 평균값을 계산하여 출력 데이터를 생성하는 방식
    - 특징 1) Spatial Invariance: 력 데이터 내의 평균값을 계산하는 것으로, 입력 데이터의 약간의 이동에 대해 일정한 성능을 보장
    - 특징 2) Reduction of Overfitting: 입력 데이터의 크기를 줄이는 효과가 있어, 모델이 입력 데이터의 세부적인 특징에 과도하게 의존하지 않도록 도와줌
    - 특징 3) Computationally Efficient: 입력 데이터의 크기를 줄이는 작업을 수행하기 때문에, 모델이 처리해야 할 계산량을 줄여줌
   - L2 Pooling
    - 입력 데이터 내에서 L2 norm 값을 계산하여 출력 데이터를 생성하는 방식
    - 입력 데이터 내의 분포를 고려한 방식으로 출력 데이터를 생성
    - 효과적인 성능 보장 X -> 최근에는 잘 사용되지 않는 기법
    - 특징 1) Shift Invariance: 입력 데이터 내의 L2 norm 값을 계산하는 것으로, 입력 데이터의 약간의 이동에 대해 일정한 성능을 보장
    - 특징 2) Local Contrast Normalization: 입력 데이터 내의 L2 norm 값을 계산하는 것으로, 입력 데이터의 로컬한 정규화(local contrast normalization) 효과를 가져옴
    - 특징 3) Computationally Efficient: 입력 데이터의 크기를 줄이는 작업을 수행하기 때문에, 모델이 처리해야 할 계산량을 줄여줌
   - Stochastic Pooling
    - 랜덤하게 값을 선택하여 출력 데이터를 생성하는 방식
    - 특징 1) Shift Invariance: 입력 데이터 내의 값을 무작위로 선택하는 것으로, 입력 데이터의 약간의 이동에 대해 일정한 성능을 보장
    - 특징 2) Reduction of Overfitting: 입력 데이터의 크기를 줄이면서 입력 데이터 내의 가장 큰 값을 선택하는 것이 아니라, 값을 무작위로 선택하는 것으로, 모델이 입력 데이터의 세부적인 특징에 과도하게 의존하지 않도록 도와줌
    - 특징 3) Robust to Local Perturbations:  입력 데이터 내의 값을 무작위로 선택하여 출력 데이터를 생성하기 때문에, 입력 데이터 내의 로컬한 변화(local perturbations)에 대해 더 강건한 성능을 보장
 - 1D convolution: 선형적인 구조를 고려하여 Text에서 사용
  - 데이터 형태: 벡터 형태로 표현
  - 데이터가 선형적인 구조, 이전 데이터와 이후 데이터 간의 관계가 중요

CatBoost
 - Gradient Boosting 기반의 머신 러닝 알고리즘 중 하나
 - 범주형 변수(categorical variables)를 효과적으로 다루는 기능을 가지고 있음
 - 특징 1) 자체적인 데이터 전처리: 범주형 변수를 자동으로 처리할 수 있도록 내부적으로 데이터를 전처리 진행 -> 별도의 데이터 변환 없이 바로 모델 학습에 사용할 수 있음
 - 특징 2) 자동적인 교차 검증: 모델 학습에 자동으로 교차 검증(cross-validation)을 적용하여 모델의 성능을 평가 -> 모델의 일반화 성능을 높일 수 있음
 - 특징 3) GPU 지원: GPU를 활용하여 모델 학습 속도를 높일 수 있음
 - 특징 4) Overfitting 방지 기능: 과적합(overfitting)을 방지하기 위한 다양한 기능을 제공
  -ex) skip tree

